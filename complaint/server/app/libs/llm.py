from openai import OpenAI
import os
from dotenv import load_dotenv

load_dotenv()

api_key = os.getenv("OPENAI_API_KEY")   

complaint_schema = {
    "name": "generate_complaint",
    "description": "ê³ ì†Œì¥ ì •ë³´ë¥¼ ìƒì„±í•œë‹¤",
    "parameters": {
        "type": "object",
        "properties": {
            "ê³ ì†Œ ì£„ëª…": {"type": "string"},
            "ê³ ì†Œì¸ ì„±ëª…": {"type": "string"},
            "ê³ ì†Œì¸ ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸": {"type": "string"},
            "ê³ ì†Œì¸ ì£¼ì†Œ": {"type": "string"},
            "ê³ ì†Œì¸ ì§ì—…": {"type": "string"},
            "ê³ ì†Œì¸ ì „í™”": {"type": "string"},
            "ê³ ì†Œì¸ ì´ë©”ì¼": {"type": "string"},
            "í”¼ê³ ì†Œì¸ ì„±ëª…": {"type": "string"},
            "í”¼ê³ ì†Œì¸ ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸": {"type": "string"},
            "í”¼ê³ ì†Œì¸ ì£¼ì†Œ": {"type": "string"},
            "í”¼ê³ ì†Œì¸ ì§ì—…": {"type": "string"},
            "í”¼ê³ ì†Œì¸ ì „í™”": {"type": "string"},
            "í”¼ê³ ì†Œì¸ ì´ë©”ì¼": {"type": "string"},
            "í”¼ê³ ì†Œì¸ ê¸°íƒ€ì‚¬í•­": {"type": "string"},
            "ê³ ì†Œ ì·¨ì§€": {"type": "string"},
            "ë²”ì£„ ì‚¬ì‹¤": {"type": "string"},
            "ê³ ì†Œ ì´ìœ ": {"type": "string"},
            "ì¦ê±° ìë£Œ": {"type": "string"},
            "ì¤‘ë³µ ê³ ì†Œ ì—¬ë¶€": {
                "type": "string",
                "enum": ["ìˆìŒ", "ì—†ìŒ"]
            },
            "ê´€ë ¨ í˜•ì‚¬ì‚¬ê±´ ìˆ˜ì‚¬ ìœ ë¬´": {
                "type": "string",
                "enum": ["ìˆìŒ", "ì—†ìŒ"]
            },
            "ê¸°íƒ€": {"type": "string"},
            "ê³ ì†Œì¼": {"type": "string"},
            "ì œì¶œ ê²½ì°°ì„œ": {"type": "string"}
        },
        "required": [
            "ê³ ì†Œ ì£„ëª…",
            "ê³ ì†Œì¸ ì„±ëª…",
            "í”¼ê³ ì†Œì¸ ê¸°íƒ€ì‚¬í•­",
            "ê³ ì†Œ ì·¨ì§€",
            "ë²”ì£„ ì‚¬ì‹¤",
            "ê³ ì†Œ ì´ìœ ",
            "ì¤‘ë³µ ê³ ì†Œ ì—¬ë¶€",
            "ê´€ë ¨ í˜•ì‚¬ì‚¬ê±´ ìˆ˜ì‚¬ ìœ ë¬´",
            "ê³ ì†Œì¼",
            "ì œì¶œ ê²½ì°°ì„œ"
        ]
    }
}

def llm_generate(query):
    client = OpenAI(
        api_key="dummy-key",
        base_url="http://localhost:9000/v1"
    )

    models = client.models.list()
    model_objs = getattr(models, "data", models) or []
    if not model_objs:
        raise RuntimeError("No models available from local server")

    model_id = getattr(model_objs[0], "id", model_objs[0])

    response = client.chat.completions.create(
        model=model_id,
        messages=[
            {
                "role": "system",
                "content": (
                    "ë„ˆëŠ” ê³ ì†Œì¥ ìë™ ì‘ì„± ì‹œìŠ¤í…œì´ë‹¤. "
                    "ë°˜ë“œì‹œ í•¨ìˆ˜ í˜¸ì¶œ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•œë‹¤."
                )
            },
            {"role": "user", "content": query},
        ],
        functions=[complaint_schema],
        function_call={"name": "generate_complaint"}  # ğŸ”¥ ê°•ì œ
    )

    msg = response.choices[0].message

    if not msg.function_call:
        raise RuntimeError("LLM did not return function_call")

    return msg.function_call.arguments  # ğŸ”¥ ì´ë¯¸ JSON ë¬¸ìì—´
