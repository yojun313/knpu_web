import { type NextRequest, NextResponse } from "next/server"
import { streamText } from "ai"
import { createOpenAI } from "@ai-sdk/openai"
import jwt from "jsonwebtoken"
import { connectDB } from "@/lib/mongodb"
import Translation from "@/lib/models/Translation"
import User from "@/lib/models/User"

export async function POST(request: NextRequest) {
  try {
    const authHeader = request.headers.get("authorization")
    const token = authHeader?.replace("Bearer ", "")

    if (!token) {
      return NextResponse.json({ message: "ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤." }, { status: 401 })
    }

    const decoded = jwt.verify(token, process.env.JWT_SECRET || "your-secret-key") as any
    const formData = await request.formData()
    const pdfFile = formData.get("pdf") as File

    if (!pdfFile) {
      return NextResponse.json({ message: "PDF íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤." }, { status: 400 })
    }

    await connectDB()

    // ì‚¬ìš©ìì˜ OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸°
    const user = await User.findById(decoded.userId)
    if (!user || !user.openaiApiKey) {
      return NextResponse.json({ message: "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤." }, { status: 400 })
    }

    // ì‚¬ìš©ìì˜ API í‚¤ë¡œ OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    const openai = createOpenAI({
      apiKey: user.openaiApiKey,
    })

    // Enhanced PDF processing
    const pdfBuffer = await pdfFile.arrayBuffer()
    const base64PDF = Buffer.from(pdfBuffer).toString("base64")

    // Create streaming response
    const encoder = new TextEncoder()
    const stream = new ReadableStream({
      async start(controller) {
        try {
          let fullTranslation = ""

          // Enhanced prompt for better PDF processing
          const result = await streamText({
            model: openai(user.preferredModel || "gpt-4o"),
            messages: [
              {
                role: "system",
                content: `ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ í•™ìˆ  ë…¼ë¬¸ ë²ˆì—­ê°€ì…ë‹ˆë‹¤. PDF ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ë²ˆì—­í•  ë•Œ ë‹¤ìŒ ê·œì¹™ì„ ë”°ë¼ì£¼ì„¸ìš”:

ğŸ“‹ **ë²ˆì—­ ê·œì¹™:**
1. í•™ìˆ ì ì´ê³  ì •í™•í•œ ë²ˆì—­ì„ ì œê³µí•©ë‹ˆë‹¤
2. ì „ë¬¸ ìš©ì–´ëŠ” ì ì ˆí•œ í•œêµ­ì–´ í•™ìˆ  ìš©ì–´ë¡œ ë²ˆì—­í•©ë‹ˆë‹¤
3. ì›ë¬¸ì˜ ì˜ë¯¸ì™€ ë‰˜ì•™ìŠ¤ë¥¼ ì •í™•íˆ ì „ë‹¬í•©ë‹ˆë‹¤
4. ë²ˆì—­ì´ ì–´ë ¤ìš´ ì „ë¬¸ ìš©ì–´ëŠ” ê´„í˜¸ ì•ˆì— ì›ë¬¸ì„ ë³‘ê¸°í•©ë‹ˆë‹¤
5. ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ë˜ í•™ìˆ ì  ë¬¸ì²´ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤

ğŸ” **PDF ë¶„ì„ ê·œì¹™:**
6. í…ìŠ¤íŠ¸ë¿ë§Œ ì•„ë‹ˆë¼ ì´ë¯¸ì§€, ê·¸ë˜í”„, í‘œ, ìˆ˜ì‹ë„ ë¶„ì„í•´ì£¼ì„¸ìš”
7. ê·¸ë˜í”„ë‚˜ ì°¨íŠ¸ê°€ ìˆë‹¤ë©´ í•´ë‹¹ ë‚´ìš©ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”
8. ìˆ˜ì‹ì´ë‚˜ ê¸°í˜¸ëŠ” LaTeX í˜•íƒœë¡œ í‘œí˜„í•˜ê±°ë‚˜ í•œê¸€ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”
9. ì´ë¯¸ì§€ë‚˜ ë‹¤ì´ì–´ê·¸ë¨ì˜ ë‚´ìš©ë„ í…ìŠ¤íŠ¸ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”
10. ì°¸ê³ ë¬¸í—Œê³¼ ì¸ìš©ì€ ì›ë¬¸ ê·¸ëŒ€ë¡œ ìœ ì§€í•©ë‹ˆë‹¤

ğŸ“„ **êµ¬ì¡° ìœ ì§€:**
11. ë…¼ë¬¸ì˜ êµ¬ì¡°(ì œëª©, ì´ˆë¡, ì„œë¡ , ë³¸ë¬¸, ê²°ë¡  ë“±)ë¥¼ ìœ ì§€í•©ë‹ˆë‹¤
12. ì„¹ì…˜ ë²ˆí˜¸ì™€ ì œëª©ì„ ëª…í™•íˆ êµ¬ë¶„í•´ì£¼ì„¸ìš”
13. í‘œë‚˜ ê·¸ë˜í”„ì˜ ìº¡ì…˜ë„ ë²ˆì—­í•´ì£¼ì„¸ìš”

ë‹¤ìŒ PDF ë…¼ë¬¸ì„ ìœ„ ê·œì¹™ì— ë”°ë¼ ì™„ì „íˆ ë²ˆì—­í•´ì£¼ì„¸ìš”:`,
              },
              {
                role: "user",
                content: `PDF íŒŒì¼ì„ ë¶„ì„í•˜ê³  ë²ˆì—­í•´ì£¼ì„¸ìš”. 

íŒŒì¼ëª…: ${pdfFile.name}
íŒŒì¼ í¬ê¸°: ${(pdfFile.size / 1024 / 1024).toFixed(2)}MB

PDF ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ì¶”ì¶œí•˜ê³ , ì´ë¯¸ì§€ë‚˜ ê·¸ë˜í”„ê°€ ìˆë‹¤ë©´ í•´ë‹¹ ë‚´ìš©ë„ ë¶„ì„í•´ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”. ìˆ˜ì‹ì´ë‚˜ íŠ¹ìˆ˜ ê¸°í˜¸ë„ ì ì ˆíˆ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.

Base64 PDF ë°ì´í„°: data:application/pdf;base64,${base64PDF.slice(0, 100000)}...

ì „ì²´ ë…¼ë¬¸ì„ ì™„ì „íˆ ë²ˆì—­í•´ì£¼ì„¸ìš”.`,
              },
            ],
            temperature: 0.1, // ë” ì¼ê´€ëœ ë²ˆì—­ì„ ìœ„í•´ ë‚®ì€ temperature
            // í† í° ì œí•œ ì™„ì „ ì œê±°
          })

          let chunkCount = 0
          const totalEstimatedChunks = Math.ceil(pdfFile.size / (1024 * 50)) // Rough estimation

          // ë²ˆì—­ ê²°ê³¼ë¥¼ ìŠ¤íŠ¸ë¦¬ë°
          for await (const delta of result.textStream) {
            fullTranslation += delta
            chunkCount++

            const progress = Math.min(25 + Math.round((chunkCount / totalEstimatedChunks) * 70), 95)

            const chunkData = encoder.encode(
              `data: ${JSON.stringify({
                content: delta,
                progress: progress,
              })}\n\n`,
            )
            controller.enqueue(chunkData)
          }

          // Save translation to database
          await Translation.create({
            userId: decoded.userId,
            originalFileName: pdfFile.name,
            originalText: `PDF íŒŒì¼ (${(pdfFile.size / 1024 / 1024).toFixed(2)}MB)`,
            translatedText: fullTranslation,
            language: "ko",
          })

          // Final progress update
          const finalChunk = encoder.encode(
            `data: ${JSON.stringify({
              content: "",
              progress: 100,
            })}\n\n`,
          )
          controller.enqueue(finalChunk)

          const doneChunk = encoder.encode(`data: [DONE]\n\n`)
          controller.enqueue(doneChunk)
          controller.close()
        } catch (error) {
          console.error("Translation streaming error:", error)
          // ì—ëŸ¬ê°€ ë°œìƒí•´ë„ ë¶€ë¶„ ë²ˆì—­ì´ë¼ë„ ì œê³µ
          const errorChunk = encoder.encode(
            `data: ${JSON.stringify({
              content: "\n\n[ë²ˆì—­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì§€ë§Œ ê°€ëŠ¥í•œ ë¶€ë¶„ê¹Œì§€ ë²ˆì—­ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.]",
              progress: 100,
            })}\n\n`,
          )
          controller.enqueue(errorChunk)
          const doneChunk = encoder.encode(`data: [DONE]\n\n`)
          controller.enqueue(doneChunk)
          controller.close()
        }
      },
    })

    return new Response(stream, {
      headers: {
        "Content-Type": "text/event-stream",
        "Cache-Control": "no-cache",
        Connection: "keep-alive",
      },
    })
  } catch (error) {
    console.error("PDF translation error:", error)
    return NextResponse.json({ message: "ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤." }, { status: 500 })
  }
}
